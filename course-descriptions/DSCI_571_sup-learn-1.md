# DSCI 571: Supervised Learning I

## Short Description
Introduction to supervised machine learning, with a focus on classification. Decision trees, logistic regression, and basic machine learning concepts such as generalization error and overfitting.

## Learning Outcomes

By the end of the course, students are expected to be able to:

1. Explain, with examples, the key differences between an unsupervised learning problem and a supervised learning problem, as well as the concept of training and test data.
2. Construct and apply a decision tree classification model, and explain how the concept of generalization error is tied to the depth of a decision tree.
3. Apply logistic regression to classification, and explain the key differences between regression and classification models.
3. Apply regularization in the context of logistic regression.
4. Build a k-th nearest-neighbor (kNN) classifier; compare and contrast parametric and non-parametric classification models.
5. Deploy support vector machine (SVM) classifiers, and explain how kernel functions are used in such classifiers.
6. Avoid the pitfalls of overfitting and reusing test sets. 


## Reference Material
* Russell, Stuart, and Peter Norvig. Artificial intelligence: a modern approach. Third Edition. 2010.
* David Poole and Alan Mackwordth. Artificial Intelligence: foundations of computational agents. 2010. (free online http://artint.info/)

## Instructor (2016-2017)
* [Giuseppe Carenini](https://www.cs.ubc.ca/~carenini/) 

_Note: information on this page is preliminary and subject to change._
