Gearing Up for Machine Learning: My Journey to GCP Professional ML Engineer
The last remaining Google Cloud certification for me to achieve is the Google Cloud Professional Machine Learning Engineer certification- this will then take me to 10/10 Google Cloud certifications. Whilst the certification has been on my radar for quite some time, I’ve postponed it to this point for various reasons:
•	It’s considered to be the most challenging Google Cloud certification by many.
•	I don’t have a mathematical or statistics background- references to functions like ReLu, Sin, Tan,  Sigmoid, Standard deviation, Lambda etc. and the visual representation of the equations involved at times overwhelm and confuse me!
•	Finding time to study the breadth and depth of the course amongst renewing existing certifications, work and family life proves challenging at the best of times.

That being said, I’m hoping I can squeeze in this certification before my next bunch of renewals are due later this year.

To help reinforce my learning, I’m creating various blog posts on the topics I’m studying in preparation for the exam, and to assist anyone else embarking upon the ML Engineer certification, or interested in learning more about machine learning. This blog post focuses on Machine Learning, how it relates to Artificial Intelligence and the more common ML model types.

Machine Learning: Unveiling the Magic
Machine learning is a subfield of artificial intelligence (AI) that deals with the ability of computers to learn without explicit programming. Imagine a child learning to recognize different animals. Through exposure to pictures and real-life encounters, the child grasps the distinguishing features of each animal. Similarly, machine learning algorithms learn from data to make data-driven predictions or uncover hidden patterns.
AI is the branch of computer science that focuses on creating intelligent agents (systems) that can reason, learn and act autonomously in a manner similar to humans. Machine learning provides the specific techniques and algorithms that enable this to happen. It's the engine that powers many of the intelligent applications we use today, from facial recognition software to recommendation systems, to self driving cars.

Supervised vs Unsupervised Learning: The Two Teachers
There are two main categories of machine learning: supervised and unsupervised
With supervised learning we provide the algorithm with labelled data, where each data point has a corresponding label or outcome (think “cat” or “dog” for an image dataset). The algorithm then learns the relationship between these features and their labels, using this knowledge to predict labels for new, unseen data.
Some example use cases for supervised learning models include:
•	Spam filtering (classifying emails as spam or not-spam)
•	Image recognition (identifying objects in an image)
•	Stock price prediction (predicting future stock prices based on historical data)

With unsupervised learning the algorithm is presented with unlabelled data and must independently discover inherent patterns or structures within it. This can involve grouping similar data points together (clustering) or identifying hidden relationships between features.
Example use cases of unsupervised leaning includes:
•	Customer segmentation (grouping customers with similar characteristics for targeted marketing)
•	Anomaly detection (identifying unusual patterns in data, like fraudulent transactions)
•	Recommendation systems (suggesting products to users based on their past purchases)

Classification vs. Regression: Model Showdown
Within supervised learning, we have two major model types: classification and regression.
Classification models are designed to assign data points to particular categories. This can be either binary classification models, where the data is classified as one item or another, or multiclass classification models where the data is classified into 3 or more categories.
Classification learning process starts with data wrangling. This is the term given for sorting the model training dataset into a useable format by resolving any inconsistencies, managing missing values and transforming the data into the required form for the model. For image classification, this may include tasks like resizing images and encoding text into numerical format.
Feature engineering is then performed, extracting the most relevant features from the data for effective classification. These features then act as fingerprints helping the model to distinguish between classification categories.
Classification models are a supervised learning model, and as such depend upon labelled datasets for training. Each datapoint has a pre-assigned label corresponding to the category it belongs to.
Model selection….
Training the model… optimisation, iteratively adjusting parameters for optimal model performance….
Making predictions… new unseen data.
Evaluation and refinement- accuracy, precision, recall… How well classifying data.
Real world examples….

Common classification models include:
o	Logistic Regression: Great for binary classifications (yes/no) and interpretable models.
o	Support Vector Machines (SVMs): Powerful for high-dimensional data.
o	Decision Trees & Random Forests: Easy to interpret and robust to irrelevant features.
•	Regression Models: These predict continuous values. Think of forecasting house prices. Common regression models include:
o	Linear Regression: The workhorse for simple relationships between features and a target value.
o	Lasso & Ridge Regression: Regularized models to prevent overfitting, especially with many features.
o	XGBoost & Random Forest Regression: Ensemble methods for improved accuracy on complex relationships.
Choosing the right model depends on the problem you're trying to solve. Stay tuned for future posts where we'll delve deeper into specific models, explore Google Cloud's amazing suite of machine learning tools, and tackle the exciting world of deep learning! In the meantime, hit the comments below and share your experiences with ML – beginner or expert, all are welcome!
